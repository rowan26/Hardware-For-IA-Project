{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52691564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'C:\\Users\\romai\\anaconda3\\envs\\hardwareAI\\Lib\\site-packages')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import psutil\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import time\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c442d287",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext tensorboard\n",
    "# Clear any logs from previous runs\n",
    "#rm -rf ./logs/\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "098e5d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, untar=True)\n",
    "data_dir = pathlib.Path(data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "939ca14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3670\n"
     ]
    }
   ],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9376ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conso_bits():\n",
    "    # Récupération des informations sur le processus en cours\n",
    "    process = psutil.Process()\n",
    "\n",
    "    # Affichage de la consommation de mémoire (en bytes)\n",
    "    return process.memory_info().rss\n",
    "\n",
    "def CPU():\n",
    "    load1, load5, load15 = psutil.getloadavg()\n",
    "    cpu_usage = (load15/os.cpu_count()) * 100\n",
    "    return cpu_usage\n",
    "def average(lst):\n",
    "    return sum(lst) / len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcfc052d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "EPOCHS=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42010595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3670 files belonging to 5 classes.\n",
      "Using 2936 files for training.\n"
     ]
    }
   ],
   "source": [
    "img_height = 180\n",
    "img_width = 180\n",
    "train_ds1 = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=BATCH_SIZE)\n",
    "\n",
    "class_names = train_ds1.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "547e1164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3670 files belonging to 5 classes.\n",
      "Using 734 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds1 = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86f9c901",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds1 = train_ds1.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds1 = val_ds1.cache().prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80808f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72edfd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "##creation du modèle\n",
    "num_classes = len(class_names)\n",
    "def get_model():\n",
    "    model = Sequential([\n",
    "      layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)), #pixel value normalization\n",
    "      layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "      layers.MaxPooling2D(),\n",
    "      layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "      layers.MaxPooling2D(),\n",
    "      layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "      layers.MaxPooling2D(),\n",
    "      layers.Flatten(),\n",
    "      layers.Dense(128, activation='relu'),\n",
    "      layers.Dense(num_classes)\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3d326a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98117a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(optimizer='adam',\n",
    "#              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7eafd904",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#history = model.fit(\n",
    "#  train_ds1,\n",
    "#  validation_data=val_ds1,\n",
    "#  epochs=epochs,\n",
    "#  callbacks=[tensorboard_callback]\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c53f093",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "train_writer = tf.summary.create_file_writer(\"logs/train/\")\n",
    "test_writer = tf.summary.create_file_writer(\"logs/test/\")\n",
    "train_step = test_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9485a226",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs\n",
      "epochs\n",
      "epochs\n",
      "epochs\n",
      "epochs\n",
      "epochs\n",
      "epochs\n",
      "epochs\n",
      "epochs\n",
      "epochs\n"
     ]
    }
   ],
   "source": [
    "a = \"run4\"\n",
    "for lr in [1e-1]:\n",
    "    train_step = test_step = 0\n",
    "    train_writer = tf.summary.create_file_writer(\"logs/train/\" + str(lr)+a)\n",
    "    test_writer = tf.summary.create_file_writer(\"logs/test/\" + str(lr)+a)\n",
    "    model = get_model()\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(\"epochs\")\n",
    "        elapsed = 0\n",
    "        cpu_use = []\n",
    "        memory_use = []\n",
    "        # Iterate through training set\n",
    "        for batch_idx, (x, y) in enumerate(train_ds1):\n",
    "            start = time.perf_counter()\n",
    "            with tf.GradientTape() as tape:\n",
    "                y_pred = model(x, training=True)\n",
    "                loss = loss_fn(y, y_pred)\n",
    "                cpu_use.append(CPU())\n",
    "                memory_use.append(conso_bits())\n",
    "            gradients = tape.gradient(loss, model.trainable_weights)\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "            acc_metric.update_state(y, y_pred)\n",
    "            elapsed += time.perf_counter() - start\n",
    "            \n",
    "            train_step += 1\n",
    "\n",
    "        # Reset accuracy in between epochs (and for testing and test)\n",
    "        with train_writer.as_default():\n",
    "                tf.summary.scalar(\"Loss\", loss, step=epoch)\n",
    "                tf.summary.scalar(\n",
    "                    \"Accuracy\", acc_metric.result(), step=epoch,\n",
    "                )\n",
    "                tf.summary.scalar(\"cpu_use\", average(cpu_use), step=epoch)\n",
    "                tf.summary.scalar(\"memory_use\", average(memory_use), step=epoch)\n",
    "                tf.summary.scalar(\"elapsed\", elapsed, step=epoch)\n",
    "        acc_metric.reset_states()\n",
    "\n",
    "        # Iterate through test set\n",
    "        for batch_idx, (x, y) in enumerate(val_ds1):\n",
    "            y_pred = model(x, training=False)\n",
    "            loss = loss_fn(y, y_pred)\n",
    "            acc_metric.update_state(y, y_pred)\n",
    "\n",
    "            with test_writer.as_default():\n",
    "                tf.summary.scalar(\"Loss\", loss, step=test_step)\n",
    "                tf.summary.scalar(\n",
    "                    \"Accuracy\", acc_metric.result(), step=test_step,\n",
    "                )\n",
    "                test_step += 1\n",
    "\n",
    "        acc_metric.reset_states()\n",
    "\n",
    "    # Reset accuracy in between epochs (and for testing and test)\n",
    "    acc_metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "150613b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Could not find `tensorboard`. Please ensure that your PATH\n",
       "contains an executable `tensorboard` program, or explicitly specify\n",
       "the path to a TensorBoard binary by setting the `TENSORBOARD_BINARY`\n",
       "environment variable."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%tensorboard --logdir logs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3b063857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#python -m tensorboard.main --logdir=logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78b0c39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
